{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🎯 **1️⃣ Feature Map (Özellik Haritası)**\n",
        "\n",
        "> 📌 *Klasik veriyi kuantum devreye “nasıl kodlayacağımızı” belirleyen devredir.*\n",
        "\n",
        "✅ Verimiz klasik (örn. `[x1, x2, x3, …]`)\n",
        "\n",
        "✅ Kuantum devrede her qubit’e bu özellikleri “gömmemiz” gerekir.\n",
        "\n",
        "✅ İşte bu **gömmeyi yapan devreye “Feature Map” denir.**\n",
        "\n",
        "\n",
        "🔷 Nasıl?\n",
        "Her özellik değeri bir dönüş açısına çevrilir:\n",
        "\n",
        "* `x_i → RX(x_i)`\n",
        "* `x_i → RZ(x_i)`\n",
        "  veya başka bir parametre.\n",
        "\n",
        "> Özet: Feature Map → veriyi qubit’lerin üzerine yerleştirir.\n",
        "> Böylece devre artık veriyi “biliyor” ve üzerinde işlem yapabilir.\n",
        "\n",
        "---\n",
        "\n",
        "# 🎯 **1️⃣ Feature Map: Matematik + Şema**\n",
        "\n",
        "### 📌 Matematik:\n",
        "\n",
        "Klasik veri noktası:\n",
        "\n",
        "$$\n",
        "\\mathbf{x} = [x_1, x_2, x_3, \\dots, x_n]\n",
        "$$\n",
        "\n",
        "Bunu kuantum durumuna gömmek için:\n",
        "\n",
        "* Her `x_i` değeri bir qubit’in açısı olarak kodlanır.\n",
        "* Örneğin:\n",
        "\n",
        "$$\n",
        "|x\\rangle = \\bigotimes_{i=1}^n RZ(x_i) RX(x_i) |0\\rangle\n",
        "$$\n",
        "\n",
        "Her qubit için:\n",
        "\n",
        "$$\n",
        "|q_i\\rangle = RZ(x_i) RX(x_i) |0\\rangle\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "\n",
        "* $RX(\\theta) = e^{-i\\theta X/2}$ → x-ekseni etrafında dönme\n",
        "* $RZ(\\theta) = e^{-i\\theta Z/2}$ → z-ekseni etrafında dönme\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 Şema:\n",
        "\n",
        "```\n",
        "Feature Map:\n",
        "  x1 ----RX(x1)----RZ(x1)----\n",
        "  x2 ----RX(x2)----RZ(x2)----\n",
        "  x3 ----RX(x3)----RZ(x3)----\n",
        "   .\n",
        "   .\n",
        "  xn ----RX(xn)----RZ(xn)----\n",
        "```\n",
        "\n",
        "Her qubit’e bir klasik özellik atanır.\n",
        "\n",
        "---\n",
        "\n",
        "# 🎯 **2️⃣ Ansatz Devresi**\n",
        "\n",
        "> 📌 *Qubit’ler üzerinde optimizasyonla öğrenilen parametrik kuantum devredir.*\n",
        "\n",
        "✅ Veriyi kodladıktan sonra: “sabit” gate’lerle ölçüm yaparsak model öğrenmez.\n",
        "\n",
        "✅ Bunun yerine üzerinde optimizasyon yapılacak serbest parametreleri olan bir devre gerekir.\n",
        "\n",
        "✅ Bu devreye **Ansatz (parametrik devre)** denir.\n",
        "\n",
        "🔷 Yapısı:\n",
        "\n",
        "* Parametrik rotasyonlar: `RY(θ), RX(θ), RZ(θ)`\n",
        "* Entanglement: CNOT zinciri gibi bağlantılar\n",
        "* Çok katmanlı olabilir (derinlik artırılır)\n",
        "\n",
        "> Özet: Ansatz → Öğrenilebilir parametreleri olan ve optimizasyonla “öğrenen” kısmı.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 🎯 **2️⃣ Ansatz: Matematik + Şema**\n",
        "\n",
        "### 📌 Matematik:\n",
        "\n",
        "Ansatz, öğrenilebilir parametreleri olan bir unitary dönüşümdür:\n",
        "\n",
        "$$\n",
        "U(\\boldsymbol{\\theta}) = U_L(\\theta_L) \\cdots U_2(\\theta_2) U_1(\\theta_1)\n",
        "$$\n",
        "\n",
        "Her katman:\n",
        "\n",
        "* Tek-qubit parametrik rotasyonlar:\n",
        "\n",
        "$$\n",
        "R(\\theta) = RY(\\theta)\n",
        "$$\n",
        "\n",
        "* Qubit’ler arası bağlantılar (CNOT, CZ)\n",
        "\n",
        "Genelde:\n",
        "\n",
        "$$\n",
        "U(\\boldsymbol{\\theta}) = \\prod_{\\text{katman}} \\left( \\bigotimes_{i=1}^n RY(\\theta_i) \\cdot \\text{entanglement} \\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 Şema:\n",
        "\n",
        "```\n",
        "Ansatz:\n",
        "Layer 1:\n",
        "  q0 ----RY(θ0)---●------------\n",
        "  q1 ----RY(θ1)---X---●--------\n",
        "  q2 ----RY(θ2)-------X---●----\n",
        "  q3 ----RY(θ3)-----------X----\n",
        "  \n",
        "Layer 2:\n",
        "  q0 ----RY(θ4)---●------------\n",
        "  q1 ----RY(θ5)---X---●--------\n",
        "  q2 ----RY(θ6)-------X---●----\n",
        "  q3 ----RY(θ7)-----------X----\n",
        "```\n",
        "\n",
        "* Her katmanda: RY rotasyonları + CNOT zinciri.\n",
        "* Derinliği artırmak için bu yapıyı tekrar et.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 🎯 **3️⃣ Torch Model**\n",
        "\n",
        "> 📌 *Kuantum devreyi çağıran klasik derin öğrenme çatısı.*\n",
        "\n",
        "✅ Biz kuantum devreyi bağımsız çalıştırmıyoruz; onu bir klasik “model” içine yerleştiriyoruz.\n",
        "\n",
        "✅ PyTorch (veya TensorFlow) burada kuantum devreyi bir katman gibi görüyor.\n",
        "\n",
        "### Yapısı:\n",
        "\n",
        "* **Forward Pass**: her veri için `circuit()` çağrılır → ölçüm sonucu alınır → çıktı üretilir\n",
        "\n",
        "* **Backward Pass**: klasik optimizasyon algoritmaları (Adam, SGD, …) ile parametreler güncellenir\n",
        "\n",
        "> Özet: Torch Model → klasik framework + kuantum katman birleşimi.\n",
        "\n",
        "\n",
        "# 🎯 **3️⃣ Torch Model: Matematik + Şema**\n",
        "\n",
        "### 📌 Matematik:\n",
        "\n",
        "Bir batch için:\n",
        "\n",
        "$$\n",
        "\\text{output} = \\text{sigmoid} \\big( \\langle 0 | U(\\boldsymbol{\\theta}) |x\\rangle \\big)\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "\n",
        "* $|x\\rangle$: Feature map ile kodlanmış veri\n",
        "* $U(\\boldsymbol{\\theta})$: Ansatz devresi\n",
        "* Ölçüm: $\\langle Z_0 \\rangle$\n",
        "\n",
        "Kayıp fonksiyonu: Binary Cross Entropy (BCE)\n",
        "\n",
        "Optimizasyon: Gradient Descent / Adam\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 Şema:\n",
        "\n",
        "```\n",
        "Torch Model:\n",
        "Input x --> Feature Map --> Ansatz --> Measurement --> Sigmoid --> Loss\n",
        "                       ^                                     |\n",
        "                       |                                     |\n",
        "                Optimize θ (Parametreler) <-------------------\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# Özet tablo:\n",
        "\n",
        "| Kavram          | Ne işe yarar?                              |\n",
        "| --------------- | ------------------------------------------ |\n",
        "| **Feature Map** | Veriyi qubit’lere kodlar                   |\n",
        "| **Ansatz**      | Öğrenilecek parametrik devre               |\n",
        "| **Torch Model** | Kuantum + klasik modeli optimize eden yapı |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 🧲 **Kuantum Rotasyon Kapıları: RX, RY, RZ**\n",
        "\n",
        "## 🎯 Ne işe yararlar?\n",
        "\n",
        "✅ Qubit’in Bloch küresi üzerindeki konumunu (ve dolayısıyla durumunu) belirli bir eksen etrafında döndürürler.\n",
        "✅ Bu dönüşlerle qubit’in durumunu değiştirir ve ölçüm sonucunu etkileriz.\n",
        "✅ Özellikle feature map ve ansatz devrelerinde temel yapı taşı olarak kullanılırlar.\n",
        "\n",
        "---\n",
        "\n",
        "# 🧲 Bloch Küresi\n",
        "\n",
        "Bir qubit’in durumunu şöyle yazabiliriz:\n",
        "\n",
        "$$\n",
        "|\\psi\\rangle = \\cos\\left(\\frac{\\theta}{2}\\right) |0\\rangle + e^{i\\phi} \\sin\\left(\\frac{\\theta}{2}\\right) |1\\rangle\n",
        "$$\n",
        "\n",
        "Bloch küresinde bu durum bir noktadır, koordinatları:\n",
        "\n",
        "$$\n",
        "x = \\sin\\theta \\cos\\phi, \\quad y = \\sin\\theta \\sin\\phi, \\quad z = \\cos\\theta\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "\n",
        "* $\\theta$: xz-düzleminde açı\n",
        "* $\\phi$: xy-düzlemindeki faz açısı\n",
        "\n",
        "---\n",
        "\n",
        "# 🔷 **RX(θ)**: X-ekseninde dönme\n",
        "\n",
        "Matematiksel olarak:\n",
        "\n",
        "$$\n",
        "R_X(\\theta) = e^{-i\\frac{\\theta}{2}X} =\n",
        "\\begin{pmatrix}\n",
        "\\cos\\frac{\\theta}{2} & -i\\sin\\frac{\\theta}{2} \\\\\n",
        "-i\\sin\\frac{\\theta}{2} & \\cos\\frac{\\theta}{2}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "✅ Bloch küresinde X-ekseni etrafında $\\theta$ kadar döner.\n",
        "✅ Başlangıçta $|0\\rangle$ durumundaki bir qubit için $RX(\\pi)$ uygularsan onu $|1\\rangle$ durumuna çevirir.\n",
        "\n",
        "---\n",
        "\n",
        "# 🔷 **RY(θ)**: Y-ekseninde dönme\n",
        "\n",
        "Matematiksel olarak:\n",
        "\n",
        "$$\n",
        "R_Y(\\theta) = e^{-i\\frac{\\theta}{2}Y} =\n",
        "\\begin{pmatrix}\n",
        "\\cos\\frac{\\theta}{2} & -\\sin\\frac{\\theta}{2} \\\\\n",
        "\\sin\\frac{\\theta}{2} & \\cos\\frac{\\theta}{2}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "✅ Bloch küresinde Y-ekseni etrafında $\\theta$ kadar döner.\n",
        "✅ Özellikle ansatz devrelerinde parametre olarak çokça kullanılır.\n",
        "\n",
        "---\n",
        "\n",
        "# 🔷 **RZ(θ)**: Z-ekseninde dönme\n",
        "\n",
        "Matematiksel olarak:\n",
        "\n",
        "$$\n",
        "R_Z(\\theta) = e^{-i\\frac{\\theta}{2}Z} =\n",
        "\\begin{pmatrix}\n",
        "e^{-i\\frac{\\theta}{2}} & 0 \\\\\n",
        "0 & e^{i\\frac{\\theta}{2}}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "✅ Bloch küresinde Z-ekseni etrafında $\\theta$ kadar döner.\n",
        "✅ Durumun fazını değiştirir; özellikle feature map’lerde kullanılır.\n",
        "\n",
        "---\n",
        "\n",
        "# 📊 Özet tablo:\n",
        "\n",
        "| Kapı      | Dönme Eksenin | Kullanım Alanı           |\n",
        "| --------- | ------------- | ------------------------ |\n",
        "| **RX(θ)** | X-ekseni      | Feature map & ansatz     |\n",
        "| **RY(θ)** | Y-ekseni      | Ansatz parametreleri     |\n",
        "| **RZ(θ)** | Z-ekseni      | Feature map (faza katkı) |\n",
        "\n",
        "---\n",
        "\n",
        "# 🔷 Neden 3 farklı dönme?\n",
        "\n",
        "Çünkü qubit’in bulunduğu Bloch küresi 3 boyutlu ve her eksende farklı bileşenleri kontrol ederiz:\n",
        "\n",
        "* $X$: Amplitüd değişimi\n",
        "* $Y$: Amplitüd + faz\n",
        "* $Z$: Saf faz değişimi\n",
        "\n",
        "Bunları kombinleyerek qubit’in istediğimiz herhangi bir kuantum durumuna ulaşmasını sağlarız.\n",
        "Çoğu devrede:\n",
        "\n",
        "$$\n",
        "R_Y(\\theta) R_Z(\\phi)\n",
        "$$\n",
        "\n",
        "kombinasyonu kullanılır. Çünkü her durumu bu ikisiyle ifade edebilirsin.\n",
        "\n",
        "---\n",
        "\n",
        "# 🔷 Görselleştirme:\n",
        "\n",
        "```\n",
        "           |1>\n",
        "            ^\n",
        "            |\n",
        "     y <----o----> x\n",
        "            |\n",
        "            v\n",
        "           |0>\n",
        "\n",
        "RX(θ): döndürme yukarı-aşağı (xz-düzleminde)\n",
        "RY(θ): döndürme öne-arkaya (yz-düzleminde)\n",
        "RZ(θ): dönme kendi etrafında (xy-düzleminde faz)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "💡 **Sonuç:**\n",
        "\n",
        "* Feature Map → Genelde RX & RZ (klasik veriyi eksenlere kodlamak için)\n",
        "* Ansatz → Genelde RY & entanglement (öğrenilecek parametreleri taşır)\n",
        ""
      ],
      "metadata": {
        "id": "nLKHelKIEFSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 qubit → 64 boyut’dan daha küçük bir veri temsiline indiriyoruz.\n",
        "(MNIST’te orijinal boyut: 28×28 = 784 → PCA ile 6 boyuta düşürüyoruz.)\n",
        "Adım 1: MNIST yükleme + ön işleme + 6 boyuta düşürme kodunu hazırla\n"
      ],
      "metadata": {
        "id": "7MKiJcQW0hNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7bLRHW6z2Ya"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn tensorflow matplotlib --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "GoRGWCuR0EaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST’i yükle\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Görüntüleri 28x28’den 784 boyuta düzleştir\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Veriyi birleştir (PCA tüm veri üzerinde fit edilmeli)\n",
        "X = np.vstack((X_train, X_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "\n",
        "print(f\"Orijinal veri boyutu: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1WA7mtp0Ece",
        "outputId": "ff30afbf-bac9-4621-c03f-49b27406e8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Orijinal veri boyutu: (70000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize et\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCA ile 6 boyuta indir\n",
        "pca = PCA(n_components=6)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"PCA sonrası boyut: {X_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHKeGs5r0Ee_",
        "outputId": "091d3f99-e650-4013-a374-b141530c7f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA sonrası boyut: (70000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train: {X_train_pca.shape}, X_test: {X_test_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4m9OuCh0EhW",
        "outputId": "d9fe13bd-773b-402f-aa91-4675cc65137b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (56000, 6), X_test: (14000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "azblTnJB0Ejp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=500)\n",
        "lr.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "y_train_pred_lr = lr.predict(X_train_pca)\n",
        "y_test_pred_lr = lr.predict(X_test_pca)\n",
        "\n",
        "train_acc_lr = accuracy_score(y_train_pca, y_train_pred_lr)\n",
        "test_acc_lr = accuracy_score(y_test_pca, y_test_pred_lr)\n",
        "\n",
        "print(f\"Lojistik Regresyon - Eğitim doğruluğu: {train_acc_lr:.2f}\")\n",
        "print(f\"Lojistik Regresyon - Test doğruluğu: {test_acc_lr:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRN-Upbe0Elm",
        "outputId": "ba3b180d-d783-4010-eb09-c36256e2c567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lojistik Regresyon - Eğitim doğruluğu: 0.73\n",
            "Lojistik Regresyon - Test doğruluğu: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "y_train_pred_rf = rf.predict(X_train_pca)\n",
        "y_test_pred_rf = rf.predict(X_test_pca)\n",
        "\n",
        "train_acc_rf = accuracy_score(y_train_pca, y_train_pred_rf)\n",
        "test_acc_rf = accuracy_score(y_test_pca, y_test_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - Eğitim doğruluğu: {train_acc_rf:.2f}\")\n",
        "print(f\"Random Forest - Test doğruluğu: {test_acc_rf:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTzKrJtb0En2",
        "outputId": "ecd37adc-77a0-4c34-8e68-0f10ffab558b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Eğitim doğruluğu: 1.00\n",
            "Random Forest - Test doğruluğu: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWPVsqBv27Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P_JUSgeJ27c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cirq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGKzqB_e0Eq6",
        "outputId": "d6ed433e-ece1-4d2f-ba8f-8ec2dfff16a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cirq\n",
            "  Downloading cirq-1.5.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cirq-aqt==1.5.0 (from cirq)\n",
            "  Downloading cirq_aqt-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting cirq-core==1.5.0 (from cirq)\n",
            "  Downloading cirq_core-1.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting cirq-google==1.5.0 (from cirq)\n",
            "  Downloading cirq_google-1.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting cirq-ionq==1.5.0 (from cirq)\n",
            "  Downloading cirq_ionq-1.5.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting cirq-pasqal==1.5.0 (from cirq)\n",
            "  Downloading cirq_pasqal-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting cirq-web==1.5.0 (from cirq)\n",
            "  Downloading cirq_web-1.5.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: requests~=2.32 in /usr/local/lib/python3.11/dist-packages (from cirq-aqt==1.5.0->cirq) (2.32.3)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (25.3.0)\n",
            "Collecting duet>=0.2.8 (from cirq-core==1.5.0->cirq)\n",
            "  Downloading duet-0.2.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: matplotlib~=3.7 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (3.10.0)\n",
            "Requirement already satisfied: networkx~=3.1 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (3.5)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (2.0.2)\n",
            "Requirement already satisfied: pandas~=2.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (2.2.2)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (2.4.0)\n",
            "Requirement already satisfied: scipy~=1.11 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (1.15.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (1.13.1)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (4.14.1)\n",
            "Requirement already satisfied: tqdm>=4.12 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (4.67.1)\n",
            "Requirement already satisfied: google-api-core>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (2.25.1)\n",
            "Requirement already satisfied: proto-plus>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from cirq-google==1.5.0->cirq) (1.26.1)\n",
            "Requirement already satisfied: protobuf<6.0,>=4.25 in /usr/local/lib/python3.11/dist-packages (from cirq-google==1.5.0->cirq) (5.29.5)\n",
            "Collecting typedunits (from cirq-google==1.5.0->cirq)\n",
            "  Downloading typedunits-0.0.1.dev20250509200845-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (1.70.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (1.71.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.0->cirq-core==1.5.0->cirq) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.0->cirq-core==1.5.0->cirq) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (2025.7.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->cirq-core==1.5.0->cirq) (1.3.0)\n",
            "Requirement already satisfied: cython>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from typedunits->cirq-google==1.5.0->cirq) (3.0.12)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.7->cirq-core==1.5.0->cirq) (1.17.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (0.6.1)\n",
            "Downloading cirq-1.5.0-py3-none-any.whl (10 kB)\n",
            "Downloading cirq_aqt-1.5.0-py3-none-any.whl (31 kB)\n",
            "Downloading cirq_core-1.5.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_google-1.5.0-py3-none-any.whl (597 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m597.5/597.5 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_ionq-1.5.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_pasqal-1.5.0-py3-none-any.whl (33 kB)\n",
            "Downloading cirq_web-1.5.0-py3-none-any.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.1/425.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duet-0.2.9-py3-none-any.whl (29 kB)\n",
            "Downloading typedunits-0.0.1.dev20250509200845-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typedunits, duet, cirq-core, cirq-web, cirq-pasqal, cirq-ionq, cirq-aqt, cirq-google, cirq\n",
            "Successfully installed cirq-1.5.0 cirq-aqt-1.5.0 cirq-core-1.5.0 cirq-google-1.5.0 cirq-ionq-1.5.0 cirq-pasqal-1.5.0 cirq-web-1.5.0 duet-0.2.9 typedunits-0.0.1.dev20250509200845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cirq\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "HZq--EQd0Es3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST yükle\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 28x28 => 784 boyut\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Birleştir (fit için)\n",
        "X = np.vstack((X_train, X_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "\n",
        "# Standartlaştırma\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCA ile 6 boyuta indir\n",
        "pca = PCA(n_components=6)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Eğitim ve test seti ayır\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train shape: {X_train_pca.shape}\")\n",
        "print(f\"X_test shape: {X_test_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irXdqKXd0Evf",
        "outputId": "9c5dba28-28ad-4c5d-9edd-8c60c1d7ede0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (56000, 6)\n",
            "X_test shape: (14000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 6\n",
        "qubits = [cirq.GridQubit(0, i) for i in range(num_qubits)]\n"
      ],
      "metadata": {
        "id": "tSjcY-H10Exf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 6\n",
        "qubits = [cirq.GridQubit(0, i) for i in range(num_qubits)]\n"
      ],
      "metadata": {
        "id": "O-flfmNh0Ez3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_map(x):\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, qubit in enumerate(qubits):\n",
        "        circuit.append(cirq.rx(x[i])(qubit))\n",
        "        circuit.append(cirq.rz(x[i])(qubit))\n",
        "    return circuit\n"
      ],
      "metadata": {
        "id": "KfNWTqgd3JTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ansatz(params):\n",
        "    circuit = cirq.Circuit()\n",
        "    k = 0\n",
        "    # 3 katmanlı ansatz\n",
        "    for _ in range(3):\n",
        "        for i, qubit in enumerate(qubits):\n",
        "            circuit.append(cirq.ry(params[k])(qubit))\n",
        "            k += 1\n",
        "        # Entanglement: CNOT zinciri\n",
        "        for i in range(num_qubits - 1):\n",
        "            circuit.append(cirq.CNOT(qubits[i], qubits[i+1]))\n",
        "    return circuit\n"
      ],
      "metadata": {
        "id": "e8_nCqES3JWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_circuit(x, params):\n",
        "    circuit = cirq.Circuit()\n",
        "    circuit += feature_map(x)\n",
        "    circuit += ansatz(params)\n",
        "    return circuit\n"
      ],
      "metadata": {
        "id": "Vp19_b0a3JX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observable = sum(cirq.Z(qubit) for qubit in qubits)\n"
      ],
      "metadata": {
        "id": "24thkHav3JaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulator = cirq.Simulator()\n",
        "\n",
        "def expectation(params, x):\n",
        "    circuit = create_circuit(x, params)\n",
        "    result = simulator.simulate_expectation_values(circuit, observables=[observable])\n",
        "    return result[0].real\n"
      ],
      "metadata": {
        "id": "siYMsLmw3JcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(params, X):\n",
        "    preds = []\n",
        "    for x in X:\n",
        "        exp_val = expectation(params, x)\n",
        "        # Sigmoid threshold\n",
        "        pred = 1 if exp_val >= 0 else 0\n",
        "        preds.append(pred)\n",
        "    return np.array(preds)\n"
      ],
      "metadata": {
        "id": "cTHIrG4L3Jel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(params, X, y):\n",
        "    preds = []\n",
        "    for x in X:\n",
        "        exp_val = expectation(params, x)\n",
        "        preds.append(1/(1 + np.exp(-exp_val)))  # sigmoid\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    # Cross-entropy\n",
        "    eps = 1e-10\n",
        "    loss_val = -np.mean(y*np.log(preds+eps) + (1 - y)*np.log(1 - preds + eps))\n",
        "    return loss_val\n"
      ],
      "metadata": {
        "id": "cRqEjsBi5-RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# Başlangıç parametreleri\n",
        "np.random.seed(42)\n",
        "init_params = np.random.uniform(0, 2*np.pi, num_qubits*3)\n",
        "\n",
        "result = minimize(loss, init_params, args=(X_train_pca, y_train_pca), method='COBYLA', options={'maxiter': 50})\n",
        "\n",
        "trained_params = result.x\n"
      ],
      "metadata": {
        "id": "rj2KdM2-5-Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = predict(trained_params, X_train_pca)\n",
        "y_test_pred = predict(trained_params, X_test_pca)\n",
        "\n",
        "train_acc = accuracy_score(y_train_pca, y_train_pred)\n",
        "test_acc = accuracy_score(y_test_pca, y_test_pred)\n",
        "\n",
        "print(f\"Cirq QNN Eğitim doğruluğu: {train_acc:.2f}\")\n",
        "print(f\"Cirq QNN Test doğruluğu: {test_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "krjAdnVo5-Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notlar:\n",
        "Bu kod CPU’da çalışır, küçük PCA boyutlu veriyle hızlı sonuç verir.\n",
        "\n",
        "maxiter artırılırsa (örneğin 100 veya 200) sonuç iyileşir ama eğitim süresi uzar.\n",
        "\n",
        "Daha gelişmiş optimizasyon için farklı algoritmalar ve parametrik devre iyileştirmeleri yapılabilir."
      ],
      "metadata": {
        "id": "77Euquer6K4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PennyLane QNN**"
      ],
      "metadata": {
        "id": "WCtBXLY96M-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane --quiet\n",
        "!pip install torch --quiet\n"
      ],
      "metadata": {
        "id": "EaS1iwtc5-YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a716cf-09f8-4f35-e3c0-35905dec4ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn tensorflow --quiet\n"
      ],
      "metadata": {
        "id": "sN6SVn2g6Mha"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "QKYo0Xuq6Mc0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri Seti\n",
        "MNIST PCA (6 boyutlu) verimizi Cirq’te hazırladığımız gibi kullanıyoruz:\n",
        "✅ X_train_pca, X_test_pca, y_train_pca, y_test_pca\n",
        "bunları direkt burada da kullanabilirsin."
      ],
      "metadata": {
        "id": "FUebduXJ-pF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "orI-BJe76Mj6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST’i yükle\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 28x28 -> 784\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Birleştir (PCA tüm veri için fit edilmeli)\n",
        "X = np.vstack((X_train, X_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "\n",
        "print(f\"Orijinal veri boyutu: {X.shape}\")\n"
      ],
      "metadata": {
        "id": "i6DhCPz66MmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c81a78f-1797-4f51-d643-442c840ee0aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Orijinal veri boyutu: (70000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=6)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"PCA sonrası boyut: {X_pca.shape}\")\n"
      ],
      "metadata": {
        "id": "JOU0L74I6MoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be1e801-f900-4959-b336-9022a3a0e678"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA sonrası boyut: (70000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train: {X_train_pca.shape}, X_test: {X_test_pca.shape}\")\n"
      ],
      "metadata": {
        "id": "gOQ1KhEz5-ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80c2958-7337-4533-e942-d3cbe6c1e5b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (56000, 6), X_test: (14000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 6\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def circuit(inputs, weights):\n",
        "    # Feature map\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(inputs[i], wires=i)\n",
        "        qml.RZ(inputs[i], wires=i)\n",
        "    # Ansatz\n",
        "    k = 0\n",
        "    for _ in range(3):  # derinlik\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(weights[k], wires=i)\n",
        "            k += 1\n",
        "        for i in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i+1])\n",
        "    return qml.expval(qml.PauliZ(0))\n"
      ],
      "metadata": {
        "id": "lqMfQ3U6-yqS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch Model\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(0.01 * torch.randn(3 * n_qubits))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = []\n",
        "        for i in range(batch_size):\n",
        "            outputs.append(circuit(x[i], self.weights))\n",
        "        return torch.stack(outputs).view(-1)\n"
      ],
      "metadata": {
        "id": "XpHI9P6J-ysw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_torch = torch.tensor(X_train_pca, dtype=torch.float32)\n",
        "X_test_torch = torch.tensor(X_test_pca, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train_pca, dtype=torch.float32)\n",
        "y_test_torch = torch.tensor(y_test_pca, dtype=torch.float32)\n",
        "\n",
        "# Sadece 0/1 etiketli örneklerle sınırlamak (opsiyonel)\n",
        "y_train_torch = (y_train_torch < 5).float()\n",
        "y_test_torch = (y_test_torch < 5).float()\n"
      ],
      "metadata": {
        "id": "r9bo9GJB-yut"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = QuantumNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "2oNn4226-yxG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"--- Epoch {epoch+1}/{epochs} başlıyor ---\")  # << BURASI EKLENDİ\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_torch)\n",
        "    loss = loss_fn(outputs, y_train_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        pred_train = (torch.sigmoid(outputs) >= 0.5).float()\n",
        "        acc_train = (pred_train == y_train_torch).float().mean()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Train Acc: {acc_train:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mn0oc5q-y0H",
        "outputId": "0999d99a-63f9-4cf8-f3e4-60a1329c449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1/10 başlıyor ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs_test = model(X_test_torch)\n",
        "    pred_test = (torch.sigmoid(outputs_test) >= 0.5).float()\n",
        "    acc_test = (pred_test == y_test_torch).float().mean()\n",
        "    print(f\"PennyLane QNN Test Doğruluğu: {acc_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "r0zc-JZn-y2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TFQ QNN: MNIST PCA (6 qubit)**"
      ],
      "metadata": {
        "id": "AOJyUIGU_RdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.15 --quiet\n",
        "pip install tensorflow-quantum --quiet\n",
        "pip install cirq --quiet\n"
      ],
      "metadata": {
        "id": "u-NlAViQ_SPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "2CdU0jwR_SSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sadece 0/1 etiketli örnekleri seçmek daha stabil sonuç verir\n",
        "y_train_bin = (y_train_pca < 5).astype(np.float32)\n",
        "y_test_bin = (y_test_pca < 5).astype(np.float32)\n",
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_pca, dtype=tf.float32)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_pca, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_bin, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test_bin, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "Vxf50qRO_SU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 6\n",
        "qubits = [cirq.GridQubit(0, i) for i in range(n_qubits)]\n"
      ],
      "metadata": {
        "id": "OD_JoPeb_SXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_circuit():\n",
        "    x = sympy.symbols('x0:6')\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, qubit in enumerate(qubits):\n",
        "        circuit.append(cirq.rx(x[i])(qubit))\n",
        "        circuit.append(cirq.rz(x[i])(qubit))\n",
        "    return circuit, list(x)\n",
        "\n",
        "feature_circuit, input_symbols = create_feature_circuit()\n"
      ],
      "metadata": {
        "id": "H1P1HEZB_SZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ansatz_circuit():\n",
        "    w = sympy.symbols('w0:18')  # 6 qubit * 3 katman\n",
        "    circuit = cirq.Circuit()\n",
        "    k = 0\n",
        "    for _ in range(3):\n",
        "        for i, qubit in enumerate(qubits):\n",
        "            circuit.append(cirq.ry(w[k])(qubit))\n",
        "            k += 1\n",
        "        for i in range(n_qubits - 1):\n",
        "            circuit.append(cirq.CNOT(qubits[i], qubits[i+1]))\n",
        "    return circuit, list(w)\n",
        "\n",
        "ansatz_circuit, weight_symbols = create_ansatz_circuit()\n"
      ],
      "metadata": {
        "id": "m4271zJn_Sb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_circuit = feature_circuit + ansatz_circuit\n"
      ],
      "metadata": {
        "id": "s7-40gP2_SeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readout_operators = [cirq.Z(qubits[0])]\n",
        "quantum_layer = tfq.layers.PQC(full_circuit, readout_operators)\n"
      ],
      "metadata": {
        "id": "MGKPKy7w_Sgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    quantum_layer,\n",
        "    tf.keras.layers.Activation('sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jKNhc2Ay_Si9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_circuits(X):\n",
        "    circuits = []\n",
        "    for x in X:\n",
        "        resolver = {f'x{i}': x[i] for i in range(len(x))}\n",
        "        circuits.append(tfq.convert_to_tensor([cirq.resolve_parameters(feature_circuit, resolver)]))\n",
        "    return tf.concat(circuits, axis=0)\n",
        "\n",
        "X_train_circuits = convert_to_circuits(X_train_pca)\n",
        "X_test_circuits = convert_to_circuits(X_test_pca)\n"
      ],
      "metadata": {
        "id": "aw9yN8g1_Sll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_circuits,\n",
        "    y_train_tensor,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test_circuits, y_test_tensor)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ew_5gG0IAtmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history.history['accuracy'][-1]\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"TFQ QNN Eğitim doğruluğu: {train_acc:.2f}\")\n",
        "print(f\"TFQ QNN Test doğruluğu: {val_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "wt1LluLUAtor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qiskit QNN**\n",
        "\n",
        "Geliştirilmiş Qiskit QNN (MNIST PCA)\n",
        "\n",
        "PCA ile 6 boyuta indirilmiş MNIST verisini (X_train_pca, y_train_pca, X_test_pca, y_test_pca) kullandığımızı varsayıyorum.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wDgCfYyBKdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import Aer\n",
        "from qiskit.utils import QuantumInstance\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "T2n8grBNBKuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_bin = (y_train_pca < 5).astype(np.float32)\n",
        "y_test_bin = (y_test_pca < 5).astype(np.float32)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_pca, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_bin, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_bin, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "GWFLdT0cBKw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Devre: Feature Map + Ansatz\n",
        "# Daha iyi bir feature map: ZZFeatureMap\n",
        "# Daha iyi bir ansatz: RealAmplitudes (entanglement & derinlik)\n",
        "\n",
        "feature_map = ZZFeatureMap(feature_dimension=6, reps=2)\n",
        "ansatz = RealAmplitudes(num_qubits=6, reps=3, entanglement='full')\n"
      ],
      "metadata": {
        "id": "3gnrVcNPBKzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantum_instance = QuantumInstance(backend=Aer.get_backend('aer_simulator_statevector'))\n",
        "\n",
        "qnn = SamplerQNN(\n",
        "    circuit=feature_map.compose(ansatz),\n",
        "    input_params=feature_map.parameters,\n",
        "    weight_params=ansatz.parameters,\n",
        "    sparse=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "PDPsE3YqBK1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridQNN(nn.Module):\n",
        "    def __init__(self, qnn):\n",
        "        super().__init__()\n",
        "        self.qnn_layer = TorchConnector(qnn)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.qnn_layer(x)\n"
      ],
      "metadata": {
        "id": "gU8EjzfNBK4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HybridQNN(qnn)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.BCELoss()\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor).squeeze()\n",
        "    loss = loss_fn(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    pred_train = (outputs.detach() >= 0.5).float()\n",
        "    acc_train = (pred_train == y_train_tensor).float().mean()\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f} | Train Acc: {acc_train:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZA7W2gr2BK6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs_test = model(X_test_tensor).squeeze()\n",
        "    pred_test = (outputs_test >= 0.5).float()\n",
        "    acc_test = (pred_test == y_test_tensor).float().mean()\n",
        "    print(f\"Qiskit QNN Test doğruluğu: {acc_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "YNojAiGVBK_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnyBhh8mFvSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}