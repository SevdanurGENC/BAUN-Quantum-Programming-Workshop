{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ **1Ô∏è‚É£ Feature Map (√ñzellik Haritasƒ±)**\n",
        "\n",
        "> üìå *Klasik veriyi kuantum devreye ‚Äúnasƒ±l kodlayacaƒüƒ±mƒ±zƒ±‚Äù belirleyen devredir.*\n",
        "\n",
        "‚úÖ Verimiz klasik (√∂rn. `[x1, x2, x3, ‚Ä¶]`)\n",
        "\n",
        "‚úÖ Kuantum devrede her qubit‚Äôe bu √∂zellikleri ‚Äúg√∂mmemiz‚Äù gerekir.\n",
        "\n",
        "‚úÖ ƒ∞≈üte bu **g√∂mmeyi yapan devreye ‚ÄúFeature Map‚Äù denir.**\n",
        "\n",
        "\n",
        "üî∑ Nasƒ±l?\n",
        "Her √∂zellik deƒüeri bir d√∂n√º≈ü a√ßƒ±sƒ±na √ßevrilir:\n",
        "\n",
        "* `x_i ‚Üí RX(x_i)`\n",
        "* `x_i ‚Üí RZ(x_i)`\n",
        "  veya ba≈üka bir parametre.\n",
        "\n",
        "> √ñzet: Feature Map ‚Üí veriyi qubit‚Äôlerin √ºzerine yerle≈ütirir.\n",
        "> B√∂ylece devre artƒ±k veriyi ‚Äúbiliyor‚Äù ve √ºzerinde i≈ülem yapabilir.\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ **1Ô∏è‚É£ Feature Map: Matematik + ≈ûema**\n",
        "\n",
        "### üìå Matematik:\n",
        "\n",
        "Klasik veri noktasƒ±:\n",
        "\n",
        "$$\n",
        "\\mathbf{x} = [x_1, x_2, x_3, \\dots, x_n]\n",
        "$$\n",
        "\n",
        "Bunu kuantum durumuna g√∂mmek i√ßin:\n",
        "\n",
        "* Her `x_i` deƒüeri bir qubit‚Äôin a√ßƒ±sƒ± olarak kodlanƒ±r.\n",
        "* √ñrneƒüin:\n",
        "\n",
        "$$\n",
        "|x\\rangle = \\bigotimes_{i=1}^n RZ(x_i) RX(x_i) |0\\rangle\n",
        "$$\n",
        "\n",
        "Her qubit i√ßin:\n",
        "\n",
        "$$\n",
        "|q_i\\rangle = RZ(x_i) RX(x_i) |0\\rangle\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "\n",
        "* $RX(\\theta) = e^{-i\\theta X/2}$ ‚Üí x-ekseni etrafƒ±nda d√∂nme\n",
        "* $RZ(\\theta) = e^{-i\\theta Z/2}$ ‚Üí z-ekseni etrafƒ±nda d√∂nme\n",
        "\n",
        "---\n",
        "\n",
        "### üìå ≈ûema:\n",
        "\n",
        "```\n",
        "Feature Map:\n",
        "  x1 ----RX(x1)----RZ(x1)----\n",
        "  x2 ----RX(x2)----RZ(x2)----\n",
        "  x3 ----RX(x3)----RZ(x3)----\n",
        "   .\n",
        "   .\n",
        "  xn ----RX(xn)----RZ(xn)----\n",
        "```\n",
        "\n",
        "Her qubit‚Äôe bir klasik √∂zellik atanƒ±r.\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ **2Ô∏è‚É£ Ansatz Devresi**\n",
        "\n",
        "> üìå *Qubit‚Äôler √ºzerinde optimizasyonla √∂ƒürenilen parametrik kuantum devredir.*\n",
        "\n",
        "‚úÖ Veriyi kodladƒ±ktan sonra: ‚Äúsabit‚Äù gate‚Äôlerle √∂l√ß√ºm yaparsak model √∂ƒürenmez.\n",
        "\n",
        "‚úÖ Bunun yerine √ºzerinde optimizasyon yapƒ±lacak serbest parametreleri olan bir devre gerekir.\n",
        "\n",
        "‚úÖ Bu devreye **Ansatz (parametrik devre)** denir.\n",
        "\n",
        "üî∑ Yapƒ±sƒ±:\n",
        "\n",
        "* Parametrik rotasyonlar: `RY(Œ∏), RX(Œ∏), RZ(Œ∏)`\n",
        "* Entanglement: CNOT zinciri gibi baƒülantƒ±lar\n",
        "* √áok katmanlƒ± olabilir (derinlik artƒ±rƒ±lƒ±r)\n",
        "\n",
        "> √ñzet: Ansatz ‚Üí √ñƒürenilebilir parametreleri olan ve optimizasyonla ‚Äú√∂ƒürenen‚Äù kƒ±smƒ±.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# üéØ **2Ô∏è‚É£ Ansatz: Matematik + ≈ûema**\n",
        "\n",
        "### üìå Matematik:\n",
        "\n",
        "Ansatz, √∂ƒürenilebilir parametreleri olan bir unitary d√∂n√º≈ü√ºmd√ºr:\n",
        "\n",
        "$$\n",
        "U(\\boldsymbol{\\theta}) = U_L(\\theta_L) \\cdots U_2(\\theta_2) U_1(\\theta_1)\n",
        "$$\n",
        "\n",
        "Her katman:\n",
        "\n",
        "* Tek-qubit parametrik rotasyonlar:\n",
        "\n",
        "$$\n",
        "R(\\theta) = RY(\\theta)\n",
        "$$\n",
        "\n",
        "* Qubit‚Äôler arasƒ± baƒülantƒ±lar (CNOT, CZ)\n",
        "\n",
        "Genelde:\n",
        "\n",
        "$$\n",
        "U(\\boldsymbol{\\theta}) = \\prod_{\\text{katman}} \\left( \\bigotimes_{i=1}^n RY(\\theta_i) \\cdot \\text{entanglement} \\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### üìå ≈ûema:\n",
        "\n",
        "```\n",
        "Ansatz:\n",
        "Layer 1:\n",
        "  q0 ----RY(Œ∏0)---‚óè------------\n",
        "  q1 ----RY(Œ∏1)---X---‚óè--------\n",
        "  q2 ----RY(Œ∏2)-------X---‚óè----\n",
        "  q3 ----RY(Œ∏3)-----------X----\n",
        "  \n",
        "Layer 2:\n",
        "  q0 ----RY(Œ∏4)---‚óè------------\n",
        "  q1 ----RY(Œ∏5)---X---‚óè--------\n",
        "  q2 ----RY(Œ∏6)-------X---‚óè----\n",
        "  q3 ----RY(Œ∏7)-----------X----\n",
        "```\n",
        "\n",
        "* Her katmanda: RY rotasyonlarƒ± + CNOT zinciri.\n",
        "* Derinliƒüi artƒ±rmak i√ßin bu yapƒ±yƒ± tekrar et.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# üéØ **3Ô∏è‚É£ Torch Model**\n",
        "\n",
        "> üìå *Kuantum devreyi √ßaƒüƒ±ran klasik derin √∂ƒürenme √ßatƒ±sƒ±.*\n",
        "\n",
        "‚úÖ Biz kuantum devreyi baƒüƒ±msƒ±z √ßalƒ±≈ütƒ±rmƒ±yoruz; onu bir klasik ‚Äúmodel‚Äù i√ßine yerle≈ütiriyoruz.\n",
        "\n",
        "‚úÖ PyTorch (veya TensorFlow) burada kuantum devreyi bir katman gibi g√∂r√ºyor.\n",
        "\n",
        "### Yapƒ±sƒ±:\n",
        "\n",
        "* **Forward Pass**: her veri i√ßin `circuit()` √ßaƒürƒ±lƒ±r ‚Üí √∂l√ß√ºm sonucu alƒ±nƒ±r ‚Üí √ßƒ±ktƒ± √ºretilir\n",
        "\n",
        "* **Backward Pass**: klasik optimizasyon algoritmalarƒ± (Adam, SGD, ‚Ä¶) ile parametreler g√ºncellenir\n",
        "\n",
        "> √ñzet: Torch Model ‚Üí klasik framework + kuantum katman birle≈üimi.\n",
        "\n",
        "\n",
        "# üéØ **3Ô∏è‚É£ Torch Model: Matematik + ≈ûema**\n",
        "\n",
        "### üìå Matematik:\n",
        "\n",
        "Bir batch i√ßin:\n",
        "\n",
        "$$\n",
        "\\text{output} = \\text{sigmoid} \\big( \\langle 0 | U(\\boldsymbol{\\theta}) |x\\rangle \\big)\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "\n",
        "* $|x\\rangle$: Feature map ile kodlanmƒ±≈ü veri\n",
        "* $U(\\boldsymbol{\\theta})$: Ansatz devresi\n",
        "* √ñl√ß√ºm: $\\langle Z_0 \\rangle$\n",
        "\n",
        "Kayƒ±p fonksiyonu: Binary Cross Entropy (BCE)\n",
        "\n",
        "Optimizasyon: Gradient Descent / Adam\n",
        "\n",
        "---\n",
        "\n",
        "### üìå ≈ûema:\n",
        "\n",
        "```\n",
        "Torch Model:\n",
        "Input x --> Feature Map --> Ansatz --> Measurement --> Sigmoid --> Loss\n",
        "                       ^                                     |\n",
        "                       |                                     |\n",
        "                Optimize Œ∏ (Parametreler) <-------------------\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# √ñzet tablo:\n",
        "\n",
        "| Kavram          | Ne i≈üe yarar?                              |\n",
        "| --------------- | ------------------------------------------ |\n",
        "| **Feature Map** | Veriyi qubit‚Äôlere kodlar                   |\n",
        "| **Ansatz**      | √ñƒürenilecek parametrik devre               |\n",
        "| **Torch Model** | Kuantum + klasik modeli optimize eden yapƒ± |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# üß≤ **Kuantum Rotasyon Kapƒ±larƒ±: RX, RY, RZ**\n",
        "\n",
        "## üéØ Ne i≈üe yararlar?\n",
        "\n",
        "‚úÖ Qubit‚Äôin Bloch k√ºresi √ºzerindeki konumunu (ve dolayƒ±sƒ±yla durumunu) belirli bir eksen etrafƒ±nda d√∂nd√ºr√ºrler.\n",
        "‚úÖ Bu d√∂n√º≈ülerle qubit‚Äôin durumunu deƒüi≈ütirir ve √∂l√ß√ºm sonucunu etkileriz.\n",
        "‚úÖ √ñzellikle feature map ve ansatz devrelerinde temel yapƒ± ta≈üƒ± olarak kullanƒ±lƒ±rlar.\n",
        "\n",
        "---\n",
        "\n",
        "# üß≤ Bloch K√ºresi\n",
        "\n",
        "Bir qubit‚Äôin durumunu ≈ü√∂yle yazabiliriz:\n",
        "\n",
        "$$\n",
        "|\\psi\\rangle = \\cos\\left(\\frac{\\theta}{2}\\right) |0\\rangle + e^{i\\phi} \\sin\\left(\\frac{\\theta}{2}\\right) |1\\rangle\n",
        "$$\n",
        "\n",
        "Bloch k√ºresinde bu durum bir noktadƒ±r, koordinatlarƒ±:\n",
        "\n",
        "$$\n",
        "x = \\sin\\theta \\cos\\phi, \\quad y = \\sin\\theta \\sin\\phi, \\quad z = \\cos\\theta\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "\n",
        "* $\\theta$: xz-d√ºzleminde a√ßƒ±\n",
        "* $\\phi$: xy-d√ºzlemindeki faz a√ßƒ±sƒ±\n",
        "\n",
        "---\n",
        "\n",
        "# üî∑ **RX(Œ∏)**: X-ekseninde d√∂nme\n",
        "\n",
        "Matematiksel olarak:\n",
        "\n",
        "$$\n",
        "R_X(\\theta) = e^{-i\\frac{\\theta}{2}X} =\n",
        "\\begin{pmatrix}\n",
        "\\cos\\frac{\\theta}{2} & -i\\sin\\frac{\\theta}{2} \\\\\n",
        "-i\\sin\\frac{\\theta}{2} & \\cos\\frac{\\theta}{2}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "‚úÖ Bloch k√ºresinde X-ekseni etrafƒ±nda $\\theta$ kadar d√∂ner.\n",
        "‚úÖ Ba≈ülangƒ±√ßta $|0\\rangle$ durumundaki bir qubit i√ßin $RX(\\pi)$ uygularsan onu $|1\\rangle$ durumuna √ßevirir.\n",
        "\n",
        "---\n",
        "\n",
        "# üî∑ **RY(Œ∏)**: Y-ekseninde d√∂nme\n",
        "\n",
        "Matematiksel olarak:\n",
        "\n",
        "$$\n",
        "R_Y(\\theta) = e^{-i\\frac{\\theta}{2}Y} =\n",
        "\\begin{pmatrix}\n",
        "\\cos\\frac{\\theta}{2} & -\\sin\\frac{\\theta}{2} \\\\\n",
        "\\sin\\frac{\\theta}{2} & \\cos\\frac{\\theta}{2}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "‚úÖ Bloch k√ºresinde Y-ekseni etrafƒ±nda $\\theta$ kadar d√∂ner.\n",
        "‚úÖ √ñzellikle ansatz devrelerinde parametre olarak √ßok√ßa kullanƒ±lƒ±r.\n",
        "\n",
        "---\n",
        "\n",
        "# üî∑ **RZ(Œ∏)**: Z-ekseninde d√∂nme\n",
        "\n",
        "Matematiksel olarak:\n",
        "\n",
        "$$\n",
        "R_Z(\\theta) = e^{-i\\frac{\\theta}{2}Z} =\n",
        "\\begin{pmatrix}\n",
        "e^{-i\\frac{\\theta}{2}} & 0 \\\\\n",
        "0 & e^{i\\frac{\\theta}{2}}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "‚úÖ Bloch k√ºresinde Z-ekseni etrafƒ±nda $\\theta$ kadar d√∂ner.\n",
        "‚úÖ Durumun fazƒ±nƒ± deƒüi≈ütirir; √∂zellikle feature map‚Äôlerde kullanƒ±lƒ±r.\n",
        "\n",
        "---\n",
        "\n",
        "# üìä √ñzet tablo:\n",
        "\n",
        "| Kapƒ±      | D√∂nme Eksenin | Kullanƒ±m Alanƒ±           |\n",
        "| --------- | ------------- | ------------------------ |\n",
        "| **RX(Œ∏)** | X-ekseni      | Feature map & ansatz     |\n",
        "| **RY(Œ∏)** | Y-ekseni      | Ansatz parametreleri     |\n",
        "| **RZ(Œ∏)** | Z-ekseni      | Feature map (faza katkƒ±) |\n",
        "\n",
        "---\n",
        "\n",
        "# üî∑ Neden 3 farklƒ± d√∂nme?\n",
        "\n",
        "√á√ºnk√º qubit‚Äôin bulunduƒüu Bloch k√ºresi 3 boyutlu ve her eksende farklƒ± bile≈üenleri kontrol ederiz:\n",
        "\n",
        "* $X$: Amplit√ºd deƒüi≈üimi\n",
        "* $Y$: Amplit√ºd + faz\n",
        "* $Z$: Saf faz deƒüi≈üimi\n",
        "\n",
        "Bunlarƒ± kombinleyerek qubit‚Äôin istediƒüimiz herhangi bir kuantum durumuna ula≈ümasƒ±nƒ± saƒülarƒ±z.\n",
        "√áoƒüu devrede:\n",
        "\n",
        "$$\n",
        "R_Y(\\theta) R_Z(\\phi)\n",
        "$$\n",
        "\n",
        "kombinasyonu kullanƒ±lƒ±r. √á√ºnk√º her durumu bu ikisiyle ifade edebilirsin.\n",
        "\n",
        "---\n",
        "\n",
        "# üî∑ G√∂rselle≈ütirme:\n",
        "\n",
        "```\n",
        "           |1>\n",
        "            ^\n",
        "            |\n",
        "     y <----o----> x\n",
        "            |\n",
        "            v\n",
        "           |0>\n",
        "\n",
        "RX(Œ∏): d√∂nd√ºrme yukarƒ±-a≈üaƒüƒ± (xz-d√ºzleminde)\n",
        "RY(Œ∏): d√∂nd√ºrme √∂ne-arkaya (yz-d√ºzleminde)\n",
        "RZ(Œ∏): d√∂nme kendi etrafƒ±nda (xy-d√ºzleminde faz)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "üí° **Sonu√ß:**\n",
        "\n",
        "* Feature Map ‚Üí Genelde RX & RZ (klasik veriyi eksenlere kodlamak i√ßin)\n",
        "* Ansatz ‚Üí Genelde RY & entanglement (√∂ƒürenilecek parametreleri ta≈üƒ±r)\n",
        ""
      ],
      "metadata": {
        "id": "nLKHelKIEFSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 qubit ‚Üí 64 boyut‚Äôdan daha k√º√ß√ºk bir veri temsiline indiriyoruz.\n",
        "(MNIST‚Äôte orijinal boyut: 28√ó28 = 784 ‚Üí PCA ile 6 boyuta d√º≈ü√ºr√ºyoruz.)\n",
        "Adƒ±m 1: MNIST y√ºkleme + √∂n i≈üleme + 6 boyuta d√º≈ü√ºrme kodunu hazƒ±rla\n"
      ],
      "metadata": {
        "id": "7MKiJcQW0hNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7bLRHW6z2Ya"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn tensorflow matplotlib --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "GoRGWCuR0EaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST‚Äôi y√ºkle\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# G√∂r√ºnt√ºleri 28x28‚Äôden 784 boyuta d√ºzle≈ütir\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Veriyi birle≈ütir (PCA t√ºm veri √ºzerinde fit edilmeli)\n",
        "X = np.vstack((X_train, X_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "\n",
        "print(f\"Orijinal veri boyutu: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1WA7mtp0Ece",
        "outputId": "ff30afbf-bac9-4621-c03f-49b27406e8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Orijinal veri boyutu: (70000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize et\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCA ile 6 boyuta indir\n",
        "pca = PCA(n_components=6)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"PCA sonrasƒ± boyut: {X_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHKeGs5r0Ee_",
        "outputId": "091d3f99-e650-4013-a374-b141530c7f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA sonrasƒ± boyut: (70000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train: {X_train_pca.shape}, X_test: {X_test_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4m9OuCh0EhW",
        "outputId": "d9fe13bd-773b-402f-aa91-4675cc65137b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (56000, 6), X_test: (14000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "azblTnJB0Ejp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=500)\n",
        "lr.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "y_train_pred_lr = lr.predict(X_train_pca)\n",
        "y_test_pred_lr = lr.predict(X_test_pca)\n",
        "\n",
        "train_acc_lr = accuracy_score(y_train_pca, y_train_pred_lr)\n",
        "test_acc_lr = accuracy_score(y_test_pca, y_test_pred_lr)\n",
        "\n",
        "print(f\"Lojistik Regresyon - Eƒüitim doƒüruluƒüu: {train_acc_lr:.2f}\")\n",
        "print(f\"Lojistik Regresyon - Test doƒüruluƒüu: {test_acc_lr:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRN-Upbe0Elm",
        "outputId": "ba3b180d-d783-4010-eb09-c36256e2c567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lojistik Regresyon - Eƒüitim doƒüruluƒüu: 0.73\n",
            "Lojistik Regresyon - Test doƒüruluƒüu: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "y_train_pred_rf = rf.predict(X_train_pca)\n",
        "y_test_pred_rf = rf.predict(X_test_pca)\n",
        "\n",
        "train_acc_rf = accuracy_score(y_train_pca, y_train_pred_rf)\n",
        "test_acc_rf = accuracy_score(y_test_pca, y_test_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - Eƒüitim doƒüruluƒüu: {train_acc_rf:.2f}\")\n",
        "print(f\"Random Forest - Test doƒüruluƒüu: {test_acc_rf:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTzKrJtb0En2",
        "outputId": "ecd37adc-77a0-4c34-8e68-0f10ffab558b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Eƒüitim doƒüruluƒüu: 1.00\n",
            "Random Forest - Test doƒüruluƒüu: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWPVsqBv27Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P_JUSgeJ27c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cirq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGKzqB_e0Eq6",
        "outputId": "d6ed433e-ece1-4d2f-ba8f-8ec2dfff16a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cirq\n",
            "  Downloading cirq-1.5.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting cirq-aqt==1.5.0 (from cirq)\n",
            "  Downloading cirq_aqt-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting cirq-core==1.5.0 (from cirq)\n",
            "  Downloading cirq_core-1.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting cirq-google==1.5.0 (from cirq)\n",
            "  Downloading cirq_google-1.5.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting cirq-ionq==1.5.0 (from cirq)\n",
            "  Downloading cirq_ionq-1.5.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting cirq-pasqal==1.5.0 (from cirq)\n",
            "  Downloading cirq_pasqal-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting cirq-web==1.5.0 (from cirq)\n",
            "  Downloading cirq_web-1.5.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: requests~=2.32 in /usr/local/lib/python3.11/dist-packages (from cirq-aqt==1.5.0->cirq) (2.32.3)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (25.3.0)\n",
            "Collecting duet>=0.2.8 (from cirq-core==1.5.0->cirq)\n",
            "  Downloading duet-0.2.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: matplotlib~=3.7 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (3.10.0)\n",
            "Requirement already satisfied: networkx~=3.1 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (3.5)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (2.0.2)\n",
            "Requirement already satisfied: pandas~=2.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (2.2.2)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (2.4.0)\n",
            "Requirement already satisfied: scipy~=1.11 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (1.15.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (1.13.1)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (4.14.1)\n",
            "Requirement already satisfied: tqdm>=4.12 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.5.0->cirq) (4.67.1)\n",
            "Requirement already satisfied: google-api-core>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (2.25.1)\n",
            "Requirement already satisfied: proto-plus>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from cirq-google==1.5.0->cirq) (1.26.1)\n",
            "Requirement already satisfied: protobuf<6.0,>=4.25 in /usr/local/lib/python3.11/dist-packages (from cirq-google==1.5.0->cirq) (5.29.5)\n",
            "Collecting typedunits (from cirq-google==1.5.0->cirq)\n",
            "  Downloading typedunits-0.0.1.dev20250509200845-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (1.70.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (1.71.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.7->cirq-core==1.5.0->cirq) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.0->cirq-core==1.5.0->cirq) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.0->cirq-core==1.5.0->cirq) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->cirq-aqt==1.5.0->cirq) (2025.7.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->cirq-core==1.5.0->cirq) (1.3.0)\n",
            "Requirement already satisfied: cython>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from typedunits->cirq-google==1.5.0->cirq) (3.0.12)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.7->cirq-core==1.5.0->cirq) (1.17.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.5.0->cirq) (0.6.1)\n",
            "Downloading cirq-1.5.0-py3-none-any.whl (10 kB)\n",
            "Downloading cirq_aqt-1.5.0-py3-none-any.whl (31 kB)\n",
            "Downloading cirq_core-1.5.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_google-1.5.0-py3-none-any.whl (597 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m597.5/597.5 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_ionq-1.5.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_pasqal-1.5.0-py3-none-any.whl (33 kB)\n",
            "Downloading cirq_web-1.5.0-py3-none-any.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m425.1/425.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duet-0.2.9-py3-none-any.whl (29 kB)\n",
            "Downloading typedunits-0.0.1.dev20250509200845-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typedunits, duet, cirq-core, cirq-web, cirq-pasqal, cirq-ionq, cirq-aqt, cirq-google, cirq\n",
            "Successfully installed cirq-1.5.0 cirq-aqt-1.5.0 cirq-core-1.5.0 cirq-google-1.5.0 cirq-ionq-1.5.0 cirq-pasqal-1.5.0 cirq-web-1.5.0 duet-0.2.9 typedunits-0.0.1.dev20250509200845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cirq\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "HZq--EQd0Es3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST y√ºkle\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 28x28 => 784 boyut\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Birle≈ütir (fit i√ßin)\n",
        "X = np.vstack((X_train, X_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "\n",
        "# Standartla≈ütƒ±rma\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCA ile 6 boyuta indir\n",
        "pca = PCA(n_components=6)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Eƒüitim ve test seti ayƒ±r\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train shape: {X_train_pca.shape}\")\n",
        "print(f\"X_test shape: {X_test_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irXdqKXd0Evf",
        "outputId": "9c5dba28-28ad-4c5d-9edd-8c60c1d7ede0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (56000, 6)\n",
            "X_test shape: (14000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 6\n",
        "qubits = [cirq.GridQubit(0, i) for i in range(num_qubits)]\n"
      ],
      "metadata": {
        "id": "tSjcY-H10Exf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 6\n",
        "qubits = [cirq.GridQubit(0, i) for i in range(num_qubits)]\n"
      ],
      "metadata": {
        "id": "O-flfmNh0Ez3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_map(x):\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, qubit in enumerate(qubits):\n",
        "        circuit.append(cirq.rx(x[i])(qubit))\n",
        "        circuit.append(cirq.rz(x[i])(qubit))\n",
        "    return circuit\n"
      ],
      "metadata": {
        "id": "KfNWTqgd3JTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ansatz(params):\n",
        "    circuit = cirq.Circuit()\n",
        "    k = 0\n",
        "    # 3 katmanlƒ± ansatz\n",
        "    for _ in range(3):\n",
        "        for i, qubit in enumerate(qubits):\n",
        "            circuit.append(cirq.ry(params[k])(qubit))\n",
        "            k += 1\n",
        "        # Entanglement: CNOT zinciri\n",
        "        for i in range(num_qubits - 1):\n",
        "            circuit.append(cirq.CNOT(qubits[i], qubits[i+1]))\n",
        "    return circuit\n"
      ],
      "metadata": {
        "id": "e8_nCqES3JWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_circuit(x, params):\n",
        "    circuit = cirq.Circuit()\n",
        "    circuit += feature_map(x)\n",
        "    circuit += ansatz(params)\n",
        "    return circuit\n"
      ],
      "metadata": {
        "id": "Vp19_b0a3JX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observable = sum(cirq.Z(qubit) for qubit in qubits)\n"
      ],
      "metadata": {
        "id": "24thkHav3JaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulator = cirq.Simulator()\n",
        "\n",
        "def expectation(params, x):\n",
        "    circuit = create_circuit(x, params)\n",
        "    result = simulator.simulate_expectation_values(circuit, observables=[observable])\n",
        "    return result[0].real\n"
      ],
      "metadata": {
        "id": "siYMsLmw3JcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(params, X):\n",
        "    preds = []\n",
        "    for x in X:\n",
        "        exp_val = expectation(params, x)\n",
        "        # Sigmoid threshold\n",
        "        pred = 1 if exp_val >= 0 else 0\n",
        "        preds.append(pred)\n",
        "    return np.array(preds)\n"
      ],
      "metadata": {
        "id": "cTHIrG4L3Jel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(params, X, y):\n",
        "    preds = []\n",
        "    for x in X:\n",
        "        exp_val = expectation(params, x)\n",
        "        preds.append(1/(1 + np.exp(-exp_val)))  # sigmoid\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    # Cross-entropy\n",
        "    eps = 1e-10\n",
        "    loss_val = -np.mean(y*np.log(preds+eps) + (1 - y)*np.log(1 - preds + eps))\n",
        "    return loss_val\n"
      ],
      "metadata": {
        "id": "cRqEjsBi5-RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# Ba≈ülangƒ±√ß parametreleri\n",
        "np.random.seed(42)\n",
        "init_params = np.random.uniform(0, 2*np.pi, num_qubits*3)\n",
        "\n",
        "result = minimize(loss, init_params, args=(X_train_pca, y_train_pca), method='COBYLA', options={'maxiter': 50})\n",
        "\n",
        "trained_params = result.x\n"
      ],
      "metadata": {
        "id": "rj2KdM2-5-Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = predict(trained_params, X_train_pca)\n",
        "y_test_pred = predict(trained_params, X_test_pca)\n",
        "\n",
        "train_acc = accuracy_score(y_train_pca, y_train_pred)\n",
        "test_acc = accuracy_score(y_test_pca, y_test_pred)\n",
        "\n",
        "print(f\"Cirq QNN Eƒüitim doƒüruluƒüu: {train_acc:.2f}\")\n",
        "print(f\"Cirq QNN Test doƒüruluƒüu: {test_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "krjAdnVo5-Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notlar:\n",
        "Bu kod CPU‚Äôda √ßalƒ±≈üƒ±r, k√º√ß√ºk PCA boyutlu veriyle hƒ±zlƒ± sonu√ß verir.\n",
        "\n",
        "maxiter artƒ±rƒ±lƒ±rsa (√∂rneƒüin 100 veya 200) sonu√ß iyile≈üir ama eƒüitim s√ºresi uzar.\n",
        "\n",
        "Daha geli≈ümi≈ü optimizasyon i√ßin farklƒ± algoritmalar ve parametrik devre iyile≈ütirmeleri yapƒ±labilir."
      ],
      "metadata": {
        "id": "77Euquer6K4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PennyLane QNN**"
      ],
      "metadata": {
        "id": "WCtBXLY96M-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane --quiet\n",
        "!pip install torch --quiet\n"
      ],
      "metadata": {
        "id": "EaS1iwtc5-YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a716cf-09f8-4f35-e3c0-35905dec4ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn tensorflow --quiet\n"
      ],
      "metadata": {
        "id": "sN6SVn2g6Mha"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "QKYo0Xuq6Mc0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri Seti\n",
        "MNIST PCA (6 boyutlu) verimizi Cirq‚Äôte hazƒ±rladƒ±ƒüƒ±mƒ±z gibi kullanƒ±yoruz:\n",
        "‚úÖ X_train_pca, X_test_pca, y_train_pca, y_test_pca\n",
        "bunlarƒ± direkt burada da kullanabilirsin."
      ],
      "metadata": {
        "id": "FUebduXJ-pF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "orI-BJe76Mj6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST‚Äôi y√ºkle\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 28x28 -> 784\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "# Birle≈ütir (PCA t√ºm veri i√ßin fit edilmeli)\n",
        "X = np.vstack((X_train, X_test))\n",
        "y = np.hstack((y_train, y_test))\n",
        "\n",
        "print(f\"Orijinal veri boyutu: {X.shape}\")\n"
      ],
      "metadata": {
        "id": "i6DhCPz66MmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c81a78f-1797-4f51-d643-442c840ee0aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Orijinal veri boyutu: (70000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=6)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"PCA sonrasƒ± boyut: {X_pca.shape}\")\n"
      ],
      "metadata": {
        "id": "JOU0L74I6MoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be1e801-f900-4959-b336-9022a3a0e678"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA sonrasƒ± boyut: (70000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"X_train: {X_train_pca.shape}, X_test: {X_test_pca.shape}\")\n"
      ],
      "metadata": {
        "id": "gOQ1KhEz5-ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80c2958-7337-4533-e942-d3cbe6c1e5b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (56000, 6), X_test: (14000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 6\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def circuit(inputs, weights):\n",
        "    # Feature map\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(inputs[i], wires=i)\n",
        "        qml.RZ(inputs[i], wires=i)\n",
        "    # Ansatz\n",
        "    k = 0\n",
        "    for _ in range(3):  # derinlik\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(weights[k], wires=i)\n",
        "            k += 1\n",
        "        for i in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i+1])\n",
        "    return qml.expval(qml.PauliZ(0))\n"
      ],
      "metadata": {
        "id": "lqMfQ3U6-yqS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch Model\n",
        "class QuantumNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(0.01 * torch.randn(3 * n_qubits))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        outputs = []\n",
        "        for i in range(batch_size):\n",
        "            outputs.append(circuit(x[i], self.weights))\n",
        "        return torch.stack(outputs).view(-1)\n"
      ],
      "metadata": {
        "id": "XpHI9P6J-ysw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_torch = torch.tensor(X_train_pca, dtype=torch.float32)\n",
        "X_test_torch = torch.tensor(X_test_pca, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train_pca, dtype=torch.float32)\n",
        "y_test_torch = torch.tensor(y_test_pca, dtype=torch.float32)\n",
        "\n",
        "# Sadece 0/1 etiketli √∂rneklerle sƒ±nƒ±rlamak (opsiyonel)\n",
        "y_train_torch = (y_train_torch < 5).float()\n",
        "y_test_torch = (y_test_torch < 5).float()\n"
      ],
      "metadata": {
        "id": "r9bo9GJB-yut"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = QuantumNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "2oNn4226-yxG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"--- Epoch {epoch+1}/{epochs} ba≈ülƒ±yor ---\")  # << BURASI EKLENDƒ∞\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_torch)\n",
        "    loss = loss_fn(outputs, y_train_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        pred_train = (torch.sigmoid(outputs) >= 0.5).float()\n",
        "        acc_train = (pred_train == y_train_torch).float().mean()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Train Acc: {acc_train:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mn0oc5q-y0H",
        "outputId": "0999d99a-63f9-4cf8-f3e4-60a1329c449d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1/10 ba≈ülƒ±yor ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs_test = model(X_test_torch)\n",
        "    pred_test = (torch.sigmoid(outputs_test) >= 0.5).float()\n",
        "    acc_test = (pred_test == y_test_torch).float().mean()\n",
        "    print(f\"PennyLane QNN Test Doƒüruluƒüu: {acc_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "r0zc-JZn-y2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TFQ QNN: MNIST PCA (6 qubit)**"
      ],
      "metadata": {
        "id": "AOJyUIGU_RdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.15 --quiet\n",
        "pip install tensorflow-quantum --quiet\n",
        "pip install cirq --quiet\n"
      ],
      "metadata": {
        "id": "u-NlAViQ_SPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "2CdU0jwR_SSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sadece 0/1 etiketli √∂rnekleri se√ßmek daha stabil sonu√ß verir\n",
        "y_train_bin = (y_train_pca < 5).astype(np.float32)\n",
        "y_test_bin = (y_test_pca < 5).astype(np.float32)\n",
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_pca, dtype=tf.float32)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_pca, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_bin, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test_bin, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "Vxf50qRO_SU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 6\n",
        "qubits = [cirq.GridQubit(0, i) for i in range(n_qubits)]\n"
      ],
      "metadata": {
        "id": "OD_JoPeb_SXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_circuit():\n",
        "    x = sympy.symbols('x0:6')\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, qubit in enumerate(qubits):\n",
        "        circuit.append(cirq.rx(x[i])(qubit))\n",
        "        circuit.append(cirq.rz(x[i])(qubit))\n",
        "    return circuit, list(x)\n",
        "\n",
        "feature_circuit, input_symbols = create_feature_circuit()\n"
      ],
      "metadata": {
        "id": "H1P1HEZB_SZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ansatz_circuit():\n",
        "    w = sympy.symbols('w0:18')  # 6 qubit * 3 katman\n",
        "    circuit = cirq.Circuit()\n",
        "    k = 0\n",
        "    for _ in range(3):\n",
        "        for i, qubit in enumerate(qubits):\n",
        "            circuit.append(cirq.ry(w[k])(qubit))\n",
        "            k += 1\n",
        "        for i in range(n_qubits - 1):\n",
        "            circuit.append(cirq.CNOT(qubits[i], qubits[i+1]))\n",
        "    return circuit, list(w)\n",
        "\n",
        "ansatz_circuit, weight_symbols = create_ansatz_circuit()\n"
      ],
      "metadata": {
        "id": "m4271zJn_Sb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_circuit = feature_circuit + ansatz_circuit\n"
      ],
      "metadata": {
        "id": "s7-40gP2_SeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readout_operators = [cirq.Z(qubits[0])]\n",
        "quantum_layer = tfq.layers.PQC(full_circuit, readout_operators)\n"
      ],
      "metadata": {
        "id": "MGKPKy7w_Sgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    quantum_layer,\n",
        "    tf.keras.layers.Activation('sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jKNhc2Ay_Si9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_circuits(X):\n",
        "    circuits = []\n",
        "    for x in X:\n",
        "        resolver = {f'x{i}': x[i] for i in range(len(x))}\n",
        "        circuits.append(tfq.convert_to_tensor([cirq.resolve_parameters(feature_circuit, resolver)]))\n",
        "    return tf.concat(circuits, axis=0)\n",
        "\n",
        "X_train_circuits = convert_to_circuits(X_train_pca)\n",
        "X_test_circuits = convert_to_circuits(X_test_pca)\n"
      ],
      "metadata": {
        "id": "aw9yN8g1_Sll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_circuits,\n",
        "    y_train_tensor,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test_circuits, y_test_tensor)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ew_5gG0IAtmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = history.history['accuracy'][-1]\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"TFQ QNN Eƒüitim doƒüruluƒüu: {train_acc:.2f}\")\n",
        "print(f\"TFQ QNN Test doƒüruluƒüu: {val_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "wt1LluLUAtor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qiskit QNN**\n",
        "\n",
        "Geli≈ütirilmi≈ü Qiskit QNN (MNIST PCA)\n",
        "\n",
        "PCA ile 6 boyuta indirilmi≈ü MNIST verisini (X_train_pca, y_train_pca, X_test_pca, y_test_pca) kullandƒ±ƒüƒ±mƒ±zƒ± varsayƒ±yorum.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wDgCfYyBKdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import Aer\n",
        "from qiskit.utils import QuantumInstance\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "T2n8grBNBKuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_bin = (y_train_pca < 5).astype(np.float32)\n",
        "y_test_bin = (y_test_pca < 5).astype(np.float32)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_pca, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_bin, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_bin, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "GWFLdT0cBKw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Devre: Feature Map + Ansatz\n",
        "# Daha iyi bir feature map: ZZFeatureMap\n",
        "# Daha iyi bir ansatz: RealAmplitudes (entanglement & derinlik)\n",
        "\n",
        "feature_map = ZZFeatureMap(feature_dimension=6, reps=2)\n",
        "ansatz = RealAmplitudes(num_qubits=6, reps=3, entanglement='full')\n"
      ],
      "metadata": {
        "id": "3gnrVcNPBKzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantum_instance = QuantumInstance(backend=Aer.get_backend('aer_simulator_statevector'))\n",
        "\n",
        "qnn = SamplerQNN(\n",
        "    circuit=feature_map.compose(ansatz),\n",
        "    input_params=feature_map.parameters,\n",
        "    weight_params=ansatz.parameters,\n",
        "    sparse=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "PDPsE3YqBK1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridQNN(nn.Module):\n",
        "    def __init__(self, qnn):\n",
        "        super().__init__()\n",
        "        self.qnn_layer = TorchConnector(qnn)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.qnn_layer(x)\n"
      ],
      "metadata": {
        "id": "gU8EjzfNBK4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HybridQNN(qnn)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.BCELoss()\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor).squeeze()\n",
        "    loss = loss_fn(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    pred_train = (outputs.detach() >= 0.5).float()\n",
        "    acc_train = (pred_train == y_train_tensor).float().mean()\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f} | Train Acc: {acc_train:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZA7W2gr2BK6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs_test = model(X_test_tensor).squeeze()\n",
        "    pred_test = (outputs_test >= 0.5).float()\n",
        "    acc_test = (pred_test == y_test_tensor).float().mean()\n",
        "    print(f\"Qiskit QNN Test doƒüruluƒüu: {acc_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "YNojAiGVBK_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnyBhh8mFvSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}